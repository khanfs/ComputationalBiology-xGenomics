{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NCBI-Datasets-APIs.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNJwgUQRlSW6qYP4i36k+6b",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/khanfs/ComputationalBiology-xGenomics/blob/main/NCBI_Datasets_APIs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **NCBI Datasets APIs**\n",
        "\n",
        "NCBI Datasets collates data from across NCBI databases. Download gene, transcript, protein and genome sequences, annotation and metadata. The Datasets API is still in alpha, and is updatioften to add new functionality. For some larger downloads, may need to download a [dehydrated bag](https://www.ncbi.nlm.nih.gov/datasets/docs/v1/how-tos/genomes/large-download/), and retrieve the individual data files at a later time. \n",
        "\n",
        "This Python package is automatically generated by the [OpenAPI Generator](https://openapi-generator.tech/) project:\n",
        "\n",
        "* API version: v1\n",
        "* Package version: 13.27.0\n",
        "* Build package: org.openapitools.codegen.languages.PythonClientCodegen\n",
        "\n",
        "**Resources**:\n",
        "\n",
        "* [NCBI Datasets](https://www.ncbi.nlm.nih.gov/datasets/)\n",
        "* [Datasets Documentation](https://www.ncbi.nlm.nih.gov/datasets/docs/v1/)\n",
        "* [ncbi-datasets-pylib](https://github.com/ncbi/datasets/tree/master/client_docs/python#installation--usage)\n",
        "* [Documentation for API Endpoints](https://github.com/ncbi/datasets/tree/master/client_docs/python#documentation-for-api-endpoints)\n",
        "* [Documentation For Models](https://github.com/ncbi/datasets/tree/master/client_docs/python#documentation-for-models)"
      ],
      "metadata": {
        "id": "9GOXtjC3ZtpC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjNUJ9RIWQj7",
        "outputId": "2ffa88b0-419d-4bfb-8d34-57ae05448338"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: ncbi-datasets-pylib in /usr/local/lib/python3.7/dist-packages (13.24.3)\n",
            "Requirement already satisfied: cachetools~=5.0 in /usr/local/lib/python3.7/dist-packages (from ncbi-datasets-pylib) (5.2.0)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.7/dist-packages (from ncbi-datasets-pylib) (57.4.0)\n",
            "Requirement already satisfied: protobuf~=3.19 in /usr/local/lib/python3.7/dist-packages (from ncbi-datasets-pylib) (3.20.1)\n",
            "Requirement already satisfied: jsonlines~=3.0 in /usr/local/lib/python3.7/dist-packages (from ncbi-datasets-pylib) (3.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.7/dist-packages (from ncbi-datasets-pylib) (2.8.2)\n",
            "Requirement already satisfied: gffutils~=0.10 in /usr/local/lib/python3.7/dist-packages (from ncbi-datasets-pylib) (0.11.0)\n",
            "Requirement already satisfied: urllib3>=1.25.3 in /usr/local/lib/python3.7/dist-packages (from ncbi-datasets-pylib) (1.26.9)\n",
            "Requirement already satisfied: jinja2~=3.0 in /usr/local/lib/python3.7/dist-packages (from ncbi-datasets-pylib) (3.1.2)\n",
            "Requirement already satisfied: argcomplete>=1.9.4 in /usr/local/lib/python3.7/dist-packages (from gffutils~=0.10->ncbi-datasets-pylib) (2.0.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from gffutils~=0.10->ncbi-datasets-pylib) (1.15.0)\n",
            "Requirement already satisfied: argh>=0.26.2 in /usr/local/lib/python3.7/dist-packages (from gffutils~=0.10->ncbi-datasets-pylib) (0.26.2)\n",
            "Requirement already satisfied: pyfaidx>=0.5.5.2 in /usr/local/lib/python3.7/dist-packages (from gffutils~=0.10->ncbi-datasets-pylib) (0.7.0)\n",
            "Requirement already satisfied: simplejson in /usr/local/lib/python3.7/dist-packages (from gffutils~=0.10->ncbi-datasets-pylib) (3.17.6)\n",
            "Requirement already satisfied: importlib-metadata<5,>=0.23 in /usr/local/lib/python3.7/dist-packages (from argcomplete>=1.9.4->gffutils~=0.10->ncbi-datasets-pylib) (4.11.4)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<5,>=0.23->argcomplete>=1.9.4->gffutils~=0.10->ncbi-datasets-pylib) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<5,>=0.23->argcomplete>=1.9.4->gffutils~=0.10->ncbi-datasets-pylib) (3.8.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.7/dist-packages (from jinja2~=3.0->ncbi-datasets-pylib) (2.0.1)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from jsonlines~=3.0->ncbi-datasets-pylib) (21.4.0)\n"
          ]
        }
      ],
      "source": [
        "! pip install ncbi-datasets-pylib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import ncbi.datasets.openapi\n",
        "from pprint import pprint\n",
        "from ncbi.datasets.openapi.api import gene_api\n",
        "from ncbi.datasets.openapi.model.rpc_status import RpcStatus\n",
        "from ncbi.datasets.openapi.model.v1_download_summary import V1DownloadSummary\n",
        "from ncbi.datasets.openapi.model.v1_fasta import V1Fasta\n",
        "from ncbi.datasets.openapi.model.v1_gene_dataset_request import V1GeneDatasetRequest\n",
        "from ncbi.datasets.openapi.model.v1_gene_dataset_request_content_type import V1GeneDatasetRequestContentType\n",
        "from ncbi.datasets.openapi.model.v1_gene_dataset_request_sort_field import V1GeneDatasetRequestSortField\n",
        "from ncbi.datasets.openapi.model.v1_gene_match import V1GeneMatch\n",
        "from ncbi.datasets.openapi.model.v1_gene_metadata import V1GeneMetadata\n",
        "from ncbi.datasets.openapi.model.v1_organism import V1Organism\n",
        "from ncbi.datasets.openapi.model.v1_organism_query_request_tax_rank_filter import V1OrganismQueryRequestTaxRankFilter\n",
        "from ncbi.datasets.openapi.model.v1_ortholog_request_content_type import V1OrthologRequestContentType\n",
        "from ncbi.datasets.openapi.model.v1_ortholog_set import V1OrthologSet\n",
        "from ncbi.datasets.openapi.model.v1_sci_name_and_ids import V1SciNameAndIds\n",
        "from ncbi.datasets.openapi.model.v1_sort_direction import V1SortDirection"
      ],
      "metadata": {
        "id": "3uQFq96-ZrBn"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ncbi.datasets"
      ],
      "metadata": {
        "id": "h5oBLkphkbJh"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **JavaScript Object Notation (JSON)** \n",
        "\n",
        "JSON is the data exchange format standard, replacing XML. JSON lines (jsonl), Newline-delimited JSON (ndjson), line-delimited JSON (ldjson) are three terms expressing the same formats primarily intended for JSON streaming. JSON Lines essentially consists of several lines where each individual line is a valid JSON object, separated by newline character `\\n`. As a result JSON lines make parsing of documents more [efficient](https://medium.com/hackernoon/json-lines-format-76353b4e588d) - makes the JSON Lines formatted file streamable. \n",
        "\n",
        "* **Serialization** is the process of encoding data into JSON format (like converting a Python list to JSON).\n",
        "\n",
        "* **Deserialization** is the process of decoding JSON data back into native objects you can work with (like reading JSON data into a Python list)."
      ],
      "metadata": {
        "id": "wsBMRavmmDtb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import jsonlines\n",
        "import os # module provides functions for interacting with the operating system\n",
        "import csv\n",
        "import zipfile\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "f6h0QBOKkiBu"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[**Pyfaidx**](https://pypi.org/project/pyfaidx/): provides an interface for creating and using this index for fast random access of DNA subsequences from huge fasta files in a “pythonic” manner. Indexing speed is comparable to samtools, and in some cases sequence retrieval is much faster (benchmark).\n",
        "\n",
        "* Shirley MD, Ma Z, Pedersen BS, Wheelan SJ. 2015. Efficient \"pythonic\" access to FASTA files using pyfaidx. PeerJ PrePrints 3:e970v1 https://doi.org/10.7287/peerj.preprints.970v1"
      ],
      "metadata": {
        "id": "lZfu8-pumOTM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyfaidx import Fasta"
      ],
      "metadata": {
        "id": "dR9G6yBymHPu"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[**google.protobuf.json_format**](https://googleapis.dev/python/protobuf/latest/google/protobuf/json_format.html): contains routines for printing protocol messages in JSON format."
      ],
      "metadata": {
        "id": "A3RlUyp_rznh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.protobuf.json_format import ParseDict"
      ],
      "metadata": {
        "id": "Frz3dIGQsWg1"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[**Collections**](https://docs.python.org/3/library/collections.html): module implements specialized containers used for storing additional data structures as alternatives to Python’s general purpose built-in data structure containers. "
      ],
      "metadata": {
        "id": "msWFxlHnsXEz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter"
      ],
      "metadata": {
        "id": "h3v9K5CNtafE"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime, timezone, timedelta"
      ],
      "metadata": {
        "id": "4113_tCltsmP"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the host is optional and defaults to https://api.ncbi.nlm.nih.gov/datasets/v1\n",
        "# See configuration.py for a list of all supported configuration parameters.\n",
        "configuration = ncbi.datasets.openapi.Configuration(\n",
        "    host = \"https://api.ncbi.nlm.nih.gov/datasets/v1\"\n",
        ")"
      ],
      "metadata": {
        "id": "ltJsCpZvx3Tp"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The client must configure the authentication and authorization parameters\n",
        "# in accordance with the API server security policy.\n",
        "# Examples for each auth method are provided below, use the example that\n",
        "# satisfies your auth use case.\n",
        "\n",
        "# Configure API key authorization: ApiKeyAuthHeader\n",
        "configuration.api_key['ApiKeyAuthHeader'] = 'YOUR_API_KEY'"
      ],
      "metadata": {
        "id": "NM3pGb0nzuJV"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Enter a context with an instance of the API client\n",
        "with ncbi.datasets.openapi.ApiClient(configuration) as api_client:\n",
        "    # Create an instance of the API class\n",
        "    api_instance = gene_api.GeneApi(api_client)\n",
        "    gene_ids = [\n",
        "        59067,\n",
        "    ] # [int] | NCBI gene ids\n",
        "    include_annotation_type = [\n",
        "        V1Fasta(\"FASTA_UNSPECIFIED\"),\n",
        "    ] # [V1Fasta] | Select additional types of annotation to include in the data package.  If unset, no annotation is provided. (optional)\n",
        "    fasta_filter = [\n",
        "        \"fasta_filter_example\",\n",
        "    ] # [str] | Limit the FASTA sequences in the datasets package to these transcript and protein accessions (optional)\n",
        "    filename = \"ncbi_dataset.zip\" # str | Output file name. (optional) if omitted the server will use the default value of \"ncbi_dataset.zip\"\n",
        "\n",
        "    # example passing only required values which don't have defaults set\n",
        "    try:\n",
        "        # Get a gene dataset by gene ID\n",
        "        api_response = api_instance.download_gene_package(gene_ids)\n",
        "        pprint(api_response)\n",
        "    except ncbi.datasets.openapi.ApiException as e:\n",
        "        print(\"Exception when calling GeneApi->download_gene_package: %s\\n\" % e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tAdsHwR8z1bs",
        "outputId": "971e5283-906b-4bec-8271-c20af9f7057e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<_io.BufferedReader name='/tmp/ncbi_dataset.zip'>\n"
          ]
        }
      ]
    }
  ]
}